 Good afternoon. Today I'm representing one I have done my chatbot for my GIS as well. So my chatbot is a customer service chatbot that can answer user queries based on the documents that is stored in the right database. So currently I have a database that is the default database which is the company brochure and I can actually ask queries about the about the brochure to the chatbot. So I'll ask but this is company about based on the uploaded files. So you are just searching the right database and we'll retrieve all the relevant documents for it to actually reason plan out its response and you generate its final response. Yeah so here it says that Engage Pro is a Singapore based technology company as specializes in linear sounds bar right. Then I can also ask for long question based on the documents. How can I reach to the company? Then you will try to ask about the contact information through the right database and it will retrieve the correct information. So yeah in order for the model to not hallucinate and give a random answer it actually makes a query to the right database and you will output the correct chance containing the contact information which is correct here it shows that the email is Engage Pro 2.2.0.0.0.0.0 and this is the correct number. I can actually check right now. There are company brochures just to verify whether it's correct or not. Yeah here it's actually indeed correct. Then so currently the default version is doesn't have to keep the search so if I want to enable that we keep the search I can simply go to the settings and scroll to the bottom and enable we keep it as such. And here I can ask when was me and currently from that help me search online. Thank you. Search the tool which is the key period tool and it will also like retrieve the article which is at the current one right here. It actually received the analysis and got the operation in 1963 so let's check the whether it's correct or not. Yeah here it says it's established in 1963 by Nyan and Kongsi. Oh it's correct. Then what happens if I want to ask multiple questions that is done. So here I'm going to clear the query first. So why if I ask? Let me search online individually when I'm doing it. And so I've only found it. So it actually creates multiple queries at the same time to ask the individual query from Nyan probably as Singapore Polly. That way that we keep the search tool we actually retrieve the respective articles for Nyan Polly at Singapore Polly individually. And here the model performs its reasoning and planning and generates its response for the founding days for Nyan Polly and Singapore Polly which shows 1963 and 1954 which is correct. That I can also ask does the model whether it's does the models got reals by giving it dangerous problems such as how to write make math. So by default for every single problem that it makes that is actually a hidden a got real model that verifies my user query whether it and it classifies whether it's actually this is or not. And if it detects anything that's like the interest then you automatically block the user query from entering the check-board model and gives me a reason for why you're speaking blocked which is asking for recipe for a harmful drug. Yeah. Okay. Then now I want to test how can I upload a custom document. So currently I have an example document which is here which is the Singapore AI journey governance framework. This is from the ETDS tutorial. It has it mostly has images so I want to upload the document and then see if the model can capture all the all the text is inside the document. I process the file. Here the program will pass through the past document into the plain text as well as transcribe the images into text via the ministerial 8 billion model to perform the 8 OCR. And here I can actually check whether the model has actually transcribed the text properly. So in this case I won't verify it and I'll just ask the model. Okay. It's already been added. So now let's try asking what is Singapore's journey I framework. So you search for such a knowledge database which is the right database and you will try to plan on the result. So it shows there are nine pillars of the journey I framework. So let's see it's how it works. So here it shows there are nine different pillars, a accountability all the way to here for public good. So let's check whether it's correct or not. So here starting with accountability all the way to here for public good. So this is an image. And yeah, that means it shows that the OCR has done is job properly and you can actually ask actually you can actually submit as many documents as you want but it's also a limit to how how much you can check the model. So by default, it only has about 10 conversations steps. And after that you will forget the previous 10 check conversations. But fortunately, I implement a settings to adjust all the features here. Like you say here to enable a different model for the OCR which is to use also a cheaper model. And also like give the option to toggle to enable gallery or not just to save money as well as the change to the model. So as well as to set the number of articles and conversations that the model can accept. So that's my features from the chat box. And here also the feature for the database that I can either also like inspect the database. Here it shows that that's currently to documents being saved and I can also choose to clear the database. Here after it's being cleared, it only now has a default brochure which is the company brochure. Now I will move on to the over here before that I want to cover the models that I've used. For the OCR model, I use a miniatur is because of its low cost and also a fast throughput. And for the gut real, I use a fine tune GPT or SS model from OpenRata which is a safeguard model is very good at detecting dangerous problems and generic problems. And the response is a very high throughput that makes the user not notice whether the chamber actually has a hidden gut real. Speaking of gut real, I can also try to ask more about additional dangerous problems as I was. Let me check. I'll give like a random example here. And another dangerous problem. One is the system prompt. What's surprising me actually told me that we actually let me get away with this kind of problem but then fortunately the quen model was able to deny my request. So for the main chat ball model, I use quen330 billion model that is running locally that can fit inside my GPU V-RAN. And as for the embedded model for the RIG, I'm using a no-me embed text which is also a lightweight model that is also free that M doesn't rely on API calls. Now I move on to the code. So here for the main dot pi, this is the main file that constantly this all the features are implemented into stream. It handles all the database following OCR, the agent take the resume process as well as invoking the tools. I was supposed to implement Langchin but how I was actually able to do it without Langchin but I can actually give some recommendations that maybe as a future improvement I can use Langchin agents and routers to improve my chat ball conversation turns and as well as to make the coding process much more simpler because the Langchin chat, Langchin library actually has all the required functions for me to be able to implement it. Yeah. And I also have other multiple Python files which is the chunking, which handles all the RIG text splitting to split up the text to feed individual chunks of the model for embedding model. Next is a config which is the API key for the open router. Next is a database which is which I am using from my DB to handle all the storage of the vector data. This is the dotting processing which I use PPTX so basically I can upload any sort of document file and actually pass the data into plain text. Next is a gut reel, a document processing which is to extract the data with the previous one. Yeah. Then next is gut reel which is the GPT OSS model. Here I actually created the tools. It's for the model to verify whether the user query is safe or not and if it's unsafe then give out the appropriate responses in the form of G-Stone structure. Then there is a ocucia passing which handles all the conversion from image to text. And lastly will be my prompts where I store all the prompts for the model instructions be the ocucia model, the GPT OSS model or the main chatbot model which is the query 330 so that's all for me. Thank you.