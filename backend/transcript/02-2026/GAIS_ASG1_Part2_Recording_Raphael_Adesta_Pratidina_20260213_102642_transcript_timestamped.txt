[00:00:00 --> 00:00:09]  Good afternoon. Today I'm representing one I have done my chatbot for my GIS as
[00:00:09 --> 00:00:18]  well. So my chatbot is a customer service chatbot that can answer user queries based on
[00:00:18 --> 00:00:24]  the documents that is stored in the right database. So currently I have a database that
[00:00:24 --> 00:00:30]  is the default database which is the company brochure and I can actually ask
[00:00:30 --> 00:00:41]  queries about the about the brochure to the chatbot. So I'll ask but this is
[00:00:41 --> 00:00:51]  company about based on the uploaded files.
[00:00:59 --> 00:01:07]  So you are just searching the right database and we'll retrieve all the relevant documents
[00:01:07 --> 00:01:14]  for it to actually reason plan out its response and you generate its final response.
[00:01:20 --> 00:01:24]  Yeah so here it says that Engage Pro is a Singapore based technology company
[00:01:24 --> 00:01:31]  as specializes in linear sounds bar right. Then I can also ask for long question
[00:01:31 --> 00:01:40]  based on the documents. How can I reach to the company?
[00:01:47 --> 00:01:52]  Then you will try to ask about the contact information through the right database and
[00:01:52 --> 00:02:01]  it will retrieve the correct information. So yeah in order for the model to not
[00:02:01 --> 00:02:07]  hallucinate and give a random answer it actually makes a query to the right database and
[00:02:07 --> 00:02:12]  you will output the correct chance containing the contact information which is correct here
[00:02:12 --> 00:02:20]  it shows that the email is Engage Pro 2.2.0.0.0.0.0 and this is the correct number. I can actually
[00:02:20 --> 00:02:30]  check right now. There are company brochures just to verify whether it's correct or not.
[00:02:36 --> 00:02:43]  Yeah here it's actually indeed correct. Then so currently the default version is
[00:02:43 --> 00:02:47]  doesn't have to keep the search so if I want to enable that we keep the search I
[00:02:48 --> 00:02:55]  can simply go to the settings and scroll to the bottom and enable we keep it as such.
[00:02:56 --> 00:03:08]  And here I can ask when was me and currently from that help me search online.
[00:03:08 --> 00:03:13]  Thank you.
[00:03:13 --> 00:03:19]  Search the tool which is the key period tool and it will also like retrieve the article which is
[00:03:20 --> 00:03:27]  at the current one right here. It actually received the analysis and got
[00:03:27 --> 00:03:31]  the operation in 1963 so let's check the whether it's correct or not.
[00:03:40 --> 00:03:46]  Yeah here it says it's established in 1963 by Nyan and Kongsi.
[00:03:47 --> 00:03:52]  Oh it's correct. Then what happens if I want to ask multiple questions that is done.
[00:03:53 --> 00:03:58]  So here I'm going to clear the query first.
[00:04:00 --> 00:04:15]  So why if I ask? Let me search online individually when I'm
[00:04:16 --> 00:04:19]  doing it.
[00:04:19 --> 00:04:21]  And so I've only found it.
[00:04:29 --> 00:04:35]  So it actually creates multiple queries at the same time to ask the individual query from Nyan
[00:04:35 --> 00:04:43]  probably as Singapore Polly. That way that we keep the search tool we actually retrieve the
[00:04:43 --> 00:04:50]  respective articles for Nyan Polly at Singapore Polly individually. And here the model
[00:04:50 --> 00:04:57]  performs its reasoning and planning and generates its response for the founding days for Nyan
[00:04:57 --> 00:05:03]  Polly and Singapore Polly which shows 1963 and 1954 which is correct.
[00:05:03 --> 00:05:12]  That I can also ask does the model whether it's does the models got reals by giving it dangerous
[00:05:12 --> 00:05:24]  problems such as how to write make math. So by default for every single problem that it makes
[00:05:24 --> 00:05:31]  that is actually a hidden a got real model that verifies my user query whether it
[00:05:31 --> 00:05:36]  and it classifies whether it's actually this is or not. And if it detects anything that's
[00:05:36 --> 00:05:41]  like the interest then you automatically block the user query from entering the
[00:05:42 --> 00:05:49]  check-board model and gives me a reason for why you're speaking blocked which is asking for
[00:05:50 --> 00:05:53]  recipe for a harmful drug. Yeah.
[00:05:55 --> 00:05:56]  Okay.
[00:05:57 --> 00:06:05]  Then now I want to test how can I upload a custom document. So currently I have an example document
[00:06:05 --> 00:06:13]  which is here which is the Singapore AI journey governance framework. This is from the ETDS
[00:06:13 --> 00:06:22]  tutorial. It has it mostly has images so I want to upload the document and then see
[00:06:23 --> 00:06:28]  if the model can capture all the all the text is inside the document.
[00:06:33 --> 00:06:46]  I process the file. Here the program will pass through the past document into the plain text
[00:06:46 --> 00:06:54]  as well as transcribe the images into text via the ministerial 8 billion model to perform the
[00:06:54 --> 00:07:01]  8 OCR. And here I can actually check whether the model has actually transcribed the text properly.
[00:07:02 --> 00:07:05]  So in this case I won't verify it and I'll just ask the model.
[00:07:05 --> 00:07:07]  Okay.
[00:07:10 --> 00:07:15]  It's already been added. So now let's try asking what is Singapore's journey
[00:07:15 --> 00:07:18]  I framework.
[00:07:26 --> 00:07:32]  So you search for such a knowledge database which is the right database and you will try to plan
[00:07:32 --> 00:07:33]  on the result.
[00:07:40 --> 00:07:45]  So it shows there are nine pillars of the journey I framework.
[00:07:47 --> 00:07:49]  So let's see it's how it works.
[00:07:55 --> 00:08:00]  So here it shows there are nine different pillars, a accountability all the way to
[00:08:00 --> 00:08:03]  here for public good. So let's check whether it's correct or not.
[00:08:05 --> 00:08:12]  So here starting with accountability all the way to here for public good. So this is an image.
[00:08:14 --> 00:08:24]  And yeah, that means it shows that the OCR has done is job properly and you can actually ask
[00:08:25 --> 00:08:33]  actually you can actually submit as many documents as you want but it's also a limit to how
[00:08:33 --> 00:08:40]  how much you can check the model. So by default, it only has about 10 conversations steps.
[00:08:40 --> 00:08:50]  And after that you will forget the previous 10 check conversations. But fortunately,
[00:08:50 --> 00:08:54]  I implement a settings to adjust all the features here.
[00:08:55 --> 00:09:02]  Like you say here to enable a different model for the OCR which is to use also a cheaper model.
[00:09:03 --> 00:09:08]  And also like give the option to toggle to enable gallery or not just to save money
[00:09:09 --> 00:09:11]  as well as the change to the model.
[00:09:11 --> 00:09:20]  So as well as to set the number of articles and conversations that the model can accept.
[00:09:23 --> 00:09:32]  So that's my features from the chat box. And here also the feature for the database that I can
[00:09:32 --> 00:09:39]  either also like inspect the database. Here it shows that that's currently to documents being
[00:09:39 --> 00:09:45]  saved and I can also choose to clear the database. Here after it's being cleared,
[00:09:45 --> 00:09:49]  it only now has a default brochure which is the company brochure.
[00:09:50 --> 00:09:56]  Now I will move on to the over here before that I want to cover the models that I've used.
[00:09:57 --> 00:10:04]  For the OCR model, I use a miniatur is because of its low cost and also a fast throughput.
[00:10:05 --> 00:10:13]  And for the gut real, I use a fine tune GPT or SS model from OpenRata which is a safeguard model
[00:10:13 --> 00:10:21]  is very good at detecting dangerous problems and generic problems. And the response
[00:10:21 --> 00:10:32]  is a very high throughput that makes the user not notice whether the chamber actually has a hidden
[00:10:32 --> 00:10:40]  gut real. Speaking of gut real, I can also try to ask more about additional dangerous problems
[00:10:41 --> 00:10:48]  as I was. Let me check. I'll give like a random example here.
[00:10:56 --> 00:11:01]  And another dangerous problem. One is the system prompt.
[00:11:01 --> 00:11:13]  What's surprising me actually told me that we actually let me get away with this kind of problem
[00:11:13 --> 00:11:21]  but then fortunately the quen model was able to deny my request. So for the main chat
[00:11:21 --> 00:11:29]  ball model, I use quen330 billion model that is running locally that can fit inside my GPU V-RAN.
[00:11:30 --> 00:11:37]  And as for the embedded model for the RIG, I'm using a no-me embed text which is also a
[00:11:37 --> 00:11:41]  lightweight model that is also free that M doesn't rely on API calls.
[00:11:44 --> 00:11:52]  Now I move on to the code. So here for the main dot pi, this is the main file that
[00:11:52 --> 00:11:58]  constantly this all the features are implemented into stream. It handles all the database
[00:11:59 --> 00:12:07]  following OCR, the agent take the resume process as well as invoking the tools.
[00:12:09 --> 00:12:17]  I was supposed to implement Langchin but how I was actually able to do it without Langchin but
[00:12:17 --> 00:12:24]  I can actually give some recommendations that maybe as a future improvement I can use
[00:12:24 --> 00:12:31]  Langchin agents and routers to improve my chat ball conversation turns and as well as to
[00:12:31 --> 00:12:38]  make the coding process much more simpler because the Langchin chat,
[00:12:39 --> 00:12:44]  Langchin library actually has all the required functions for me to be able to implement it.
[00:12:44 --> 00:12:53]  Yeah. And I also have other multiple Python files which is the chunking, which handles all the
[00:12:53 --> 00:13:01]  RIG text splitting to split up the text to feed individual chunks of the model for embedding model.
[00:13:02 --> 00:13:08]  Next is a config which is the API key for the open router. Next is a database which is
[00:13:08 --> 00:13:14]  which I am using from my DB to handle all the storage of the vector data.
[00:13:15 --> 00:13:22]  This is the dotting processing which I use PPTX so basically I can upload any sort of
[00:13:23 --> 00:13:31]  document file and actually pass the data into plain text. Next is a gut reel,
[00:13:31 --> 00:13:37]  a document processing which is to extract the data with the previous one.
[00:13:39 --> 00:13:46]  Yeah. Then next is gut reel which is the GPT OSS model. Here I actually created the tools.
[00:13:47 --> 00:13:56]  It's for the model to verify whether the user query is safe or not and if it's unsafe then
[00:13:57 --> 00:14:03]  give out the appropriate responses in the form of G-Stone structure.
[00:14:05 --> 00:14:13]  Then there is a ocucia passing which handles all the conversion from image to text.
[00:14:13 --> 00:14:19]  And lastly will be my prompts where I store all the prompts for the model instructions
[00:14:19 --> 00:14:27]  be the ocucia model, the GPT OSS model or the main chatbot model which is the query 330
[00:14:27 --> 00:14:30]  so that's all for me. Thank you.
